{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-CBOW-Model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithya-tp/PyTorch-Notebooks/blob/master/03_CBOW_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2AN6Wc9AReR",
        "colab_type": "text"
      },
      "source": [
        "# ***Setting up imports and training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd3Hoq3Z__A9",
        "colab_type": "code",
        "outputId": "625f7629-5da9-4a9f-dcf8-a86467e19d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2d22229c70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8NLDE2hAPmX",
        "colab_type": "code",
        "outputId": "ba263a01-adb9-48d7-b332-dbee08759622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "raw_text_list = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n",
        "vocab = set(raw_text_list)\n",
        "vocab_dict = {word:i for i, word in enumerate(vocab)}\n",
        "\n",
        "training_data = []\n",
        "for index in range(2, len(raw_text_list)-2):\n",
        "  context = [raw_text_list[index-2], raw_text_list[index-1], \n",
        "             raw_text_list[index+1], raw_text_list[index+2]]\n",
        "  target = raw_text_list[index]\n",
        "  training_data.append((context, target))\n",
        "\n",
        "# let us try printing out the first three and the last three examples of the training data\n",
        "print(training_data[:3])\n",
        "print(training_data[-3:])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study')]\n",
            "[(['spirits', 'of', 'computer', 'with'], 'the'), (['of', 'the', 'with', 'our'], 'computer'), (['the', 'computer', 'our', 'spells.'], 'with')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bDyHcPrCZd3",
        "colab_type": "text"
      },
      "source": [
        "# ***Defining some utility functions and the CBOW model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnYsniamCNzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function that gives us directions on which rows of embeddings we should pick up\n",
        "def get_lookup_tensor(context, vocab_dict):\n",
        "  idxs = [vocab_dict[word] for word in context]\n",
        "  return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O8jAa69C8tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "  \n",
        "  def __init__(self, len_vocab, CONTEXT_SIZE, EMBEDDING_DIM):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.embeddings = nn.Embedding(len_vocab, EMBEDDING_DIM)\n",
        "    self.linear1 = nn.Linear(EMBEDDING_DIM, 128)\n",
        "    self.linear2 = nn.Linear(128, len_vocab)\n",
        "    \n",
        "  def forward(self, lookup_tensor):\n",
        "    embeds = torch.sum(self.embeddings(lookup_tensor), dim=0).view((1, -1))\n",
        "    out = F.relu(self.linear1(embeds))\n",
        "    out = F.log_softmax(self.linear2(out), dim=-1)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSp9HR7KHQlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f0bfe5a-ebfc-4d41-eb77-a9bd08a770d1"
      },
      "source": [
        "model = CBOW(len(vocab), CONTEXT_SIZE, EMBEDDING_DIM)\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "  total_loss = 0\n",
        "  for context, target in training_data:\n",
        "    lookup_tensor = get_lookup_tensor(context, vocab_dict)\n",
        "    model.zero_grad()\n",
        "    out = model(lookup_tensor)\n",
        "    loss = loss_function(out, torch.tensor([vocab_dict[target]], dtype=torch.long))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  losses.append(total_loss)\n",
        "print(losses)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[237.258868932724, 203.09004044532776, 177.6140923500061, 156.5703957080841, 138.30288171768188, 122.156085729599, 107.72539806365967, 94.76788902282715, 83.21345710754395, 72.86995792388916, 63.681771993637085, 55.542712926864624, 48.380168437957764, 42.11221408843994, 36.652937173843384, 31.941946268081665, 27.900954246520996, 24.45238447189331, 21.522731065750122, 19.040234088897705, 16.932087421417236, 15.14035153388977, 13.618410110473633, 12.316611289978027, 11.198600769042969, 10.23484754562378, 9.400622844696045, 8.674383163452148, 8.037551879882812, 7.474445819854736, 6.977100372314453, 6.533580780029297, 6.137628078460693, 5.782089710235596, 5.459830284118652, 5.1691389083862305, 4.90471887588501, 4.661912441253662, 4.441378593444824, 4.238258361816406, 4.050832271575928, 3.8771862983703613, 3.7175607681274414, 3.568871021270752, 3.4299850463867188, 3.300971031188965, 3.180060386657715, 3.067263603210449, 2.9617419242858887, 2.8621020317077637, 2.7687530517578125, 2.6804909706115723, 2.59744930267334, 2.5186734199523926, 2.444246768951416, 2.3737258911132812, 2.306891441345215, 2.2433524131774902, 2.1827502250671387, 2.125058174133301, 2.0704092979431152, 2.0180187225341797, 1.96791410446167, 1.9201602935791016, 1.8744564056396484, 1.8306574821472168, 1.7887635231018066, 1.748521327972412, 1.7098846435546875, 1.6729798316955566, 1.6372466087341309, 1.6030893325805664, 1.5699377059936523, 1.5383515357971191, 1.5077247619628906, 1.4781451225280762, 1.4497838020324707, 1.422196388244629, 1.3957242965698242, 1.3699464797973633, 1.3451743125915527, 1.321249008178711, 1.2979583740234375, 1.275498390197754, 1.2537007331848145, 1.2325677871704102, 1.2121434211730957, 1.192234992980957, 1.172999382019043, 1.1542768478393555, 1.1360740661621094, 1.1184492111206055, 1.101262092590332, 1.084609031677246, 1.0683708190917969, 1.0526084899902344, 1.0372610092163086, 1.0222768783569336, 1.0077400207519531, 0.9935064315795898]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6QRgTEoUS3p",
        "colab_type": "text"
      },
      "source": [
        "# ***Sample Test for the Trained Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU9YHQDXirS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predicted_word(pred_tensor):\n",
        "  pred_index = (torch.abs(pred_tensor.max().item() - pred_tensor<0.0001).nonzero()[0][1].item())\n",
        "  for index, word in enumerate(vocab_dict):\n",
        "    if index == pred_index:\n",
        "      return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE8axcLiUWcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f0f953e3-d2db-4265-c61a-8807ef943f07"
      },
      "source": [
        "sample_context = [\"a\", \"process\", \"directed\", \"by\"]\n",
        "pred_tensor = model(get_lookup_tensor(sample_context, vocab_dict))\n",
        "word = get_predicted_word(pred_tensor)\n",
        "print(\"Prediction of central word: \", word)\n",
        "print(\"Predicted sentence : {} {} {} {} {}\".format(sample_context[0], sample_context[1], word, sample_context[2], sample_context[3]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of central word:  is\n",
            "Predicted sentence : a process is directed by\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}