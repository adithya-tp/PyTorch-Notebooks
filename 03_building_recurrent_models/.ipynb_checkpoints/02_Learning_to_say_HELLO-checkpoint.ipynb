{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the sequence \"hello\" one letter at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y data. The task is for the rnn to learn the sequence \"hello\" (or rather, produce the next corresponding letter in the sequence hello, since we aren't feeding the output of the lstm itself as the next input, are we?)\n",
    "idx2char = ['h', 'e', 'l', 'o']\n",
    "x_data = [0, 1, 2, 2]\n",
    "y_data = [1, 2, 2, 3]\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "# converting data using one_hot_lookup tables (this is sort of a foundation before we move to Embedding Layers)\n",
    "x_data_ohe = [one_hot_lookup[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nodes on our computational graph\n",
    "inputs = Variable(torch.Tensor(x_data_ohe))\n",
    "labels = Variable(torch.LongTensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparams\n",
    "num_classes = 4\n",
    "input_size = 4\n",
    "hidden_size = 4 # we don't want to feed the hidden tensor to a linear layer to scale up/down the output to ohe dimensions, since this task is easy enough.\n",
    "batch_size = 1 # a single slice of bread\n",
    "seq_len = 1 # we are breaking up the bread and feeding it in letter by letter (1st case in previous notebook)\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our model\n",
    "class RecurrentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecurrentModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, hidden, x):\n",
    "        # reshape input to be batch first.\n",
    "        x = x.view(batch_size, seq_len, input_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        return hidden, out.view(-1, num_classes) # would be [1 x 4] in our case\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentModel(\n",
      "  (rnn): RNN(4, 4, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate model, loss, and optimizer\n",
    "recurrent_model = RecurrentModel()\n",
    "print(recurrent_model)\n",
    "\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(recurrent_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted string: oloo\n",
      "Epoch: 1, loss: 5.427931785583496\n",
      "\n",
      "\n",
      "predicted string: lloo\n",
      "Epoch: 2, loss: 4.51144552230835\n",
      "\n",
      "\n",
      "predicted string: llll\n",
      "Epoch: 3, loss: 3.9218273162841797\n",
      "\n",
      "\n",
      "predicted string: llll\n",
      "Epoch: 4, loss: 3.5491323471069336\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 5, loss: 3.2913217544555664\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 6, loss: 3.0916199684143066\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 7, loss: 2.918445110321045\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 8, loss: 2.745919704437256\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 9, loss: 2.5968942642211914\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 10, loss: 2.4741508960723877\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 11, loss: 2.37528395652771\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 12, loss: 2.2958881855010986\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 13, loss: 2.2356719970703125\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 14, loss: 2.1860783100128174\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 15, loss: 2.14987850189209\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 16, loss: 2.120878219604492\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 17, loss: 2.097287178039551\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 18, loss: 2.079995632171631\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 19, loss: 2.0647614002227783\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 20, loss: 2.053013801574707\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 21, loss: 2.0427117347717285\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 22, loss: 2.0334019660949707\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 23, loss: 2.0261175632476807\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 24, loss: 2.018738269805908\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 25, loss: 2.0129036903381348\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 26, loss: 2.0073182582855225\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 27, loss: 2.0023019313812256\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 28, loss: 1.9980700016021729\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 29, loss: 1.9937583208084106\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 30, loss: 1.9903461933135986\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 31, loss: 1.986778736114502\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 32, loss: 1.9838621616363525\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 33, loss: 1.9809459447860718\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 34, loss: 1.9783508777618408\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 35, loss: 1.9759700298309326\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 36, loss: 1.9736354351043701\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 37, loss: 1.971646785736084\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 38, loss: 1.9695663452148438\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 39, loss: 1.96783447265625\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 40, loss: 1.9659992456436157\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 41, loss: 1.964461326599121\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 42, loss: 1.9628363847732544\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 43, loss: 1.9614393711090088\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 44, loss: 1.960003137588501\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 45, loss: 1.9587247371673584\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 46, loss: 1.9574377536773682\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 47, loss: 1.9562628269195557\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 48, loss: 1.9551019668579102\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 49, loss: 1.9540176391601562\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 50, loss: 1.9529582262039185\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 51, loss: 1.951956033706665\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 52, loss: 1.9509810209274292\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 53, loss: 1.9500516653060913\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 54, loss: 1.9491465091705322\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 55, loss: 1.9482823610305786\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 56, loss: 1.947436809539795\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 57, loss: 1.9466297626495361\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 58, loss: 1.945834994316101\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 59, loss: 1.9450783729553223\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 60, loss: 1.9443285465240479\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 61, loss: 1.9436161518096924\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 62, loss: 1.9429051876068115\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 63, loss: 1.9422311782836914\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 64, loss: 1.9415560960769653\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 65, loss: 1.940915584564209\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 66, loss: 1.940272569656372\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 67, loss: 1.9396603107452393\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 68, loss: 1.939048171043396\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 69, loss: 1.938460111618042\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 70, loss: 1.9378762245178223\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 71, loss: 1.9373095035552979\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 72, loss: 1.936751365661621\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 73, loss: 1.936203956604004\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 74, loss: 1.9356694221496582\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 75, loss: 1.935140609741211\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 76, loss: 1.9346263408660889\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 77, loss: 1.9341155290603638\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 78, loss: 1.9336187839508057\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 79, loss: 1.9331262111663818\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 80, loss: 1.9326443672180176\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 81, loss: 1.9321696758270264\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 82, loss: 1.9317020177841187\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 83, loss: 1.9312431812286377\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 84, loss: 1.9307889938354492\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 85, loss: 1.930344581604004\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 86, loss: 1.9299042224884033\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 87, loss: 1.9294720888137817\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 88, loss: 1.9290452003479004\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 89, loss: 1.9286247491836548\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 90, loss: 1.9282112121582031\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 91, loss: 1.9278018474578857\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 92, loss: 1.9273992776870728\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 93, loss: 1.927001714706421\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 94, loss: 1.9266095161437988\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 95, loss: 1.926222801208496\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 96, loss: 1.9258403778076172\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 97, loss: 1.9254640340805054\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 98, loss: 1.9250915050506592\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 99, loss: 1.9247239828109741\n",
      "\n",
      "\n",
      "predicted string: elll\n",
      "Epoch: 100, loss: 1.9243615865707397\n",
      "\n",
      "\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = recurrent_model.init_hidden()\n",
    "    \n",
    "    print(\"predicted string: \", end=\"\")\n",
    "    for inp, label in zip(inputs, labels):\n",
    "        hidden, output = recurrent_model(hidden, inp)\n",
    "        val, idx = output.max(1)\n",
    "        print(idx2char[idx.data[0]], end=\"\")\n",
    "        loss += loss_criterion(output, torch.LongTensor([label]))\n",
    "    print(\"\")\n",
    "    print(\"Epoch: {}, loss: {}\\n\\n\".format(epoch + 1, loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"Learning finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
